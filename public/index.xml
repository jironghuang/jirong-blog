<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jirong&#39;s sandbox on Jirong&#39;s sandbox</title>
    <link>/</link>
    <description>Recent content in Jirong&#39;s sandbox on Jirong&#39;s sandbox</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Prototype Pair Trading Strategy for Silver ETFs</title>
      <link>/post/prototype-of-pair-trading-strategy-for-silver-etfs/</link>
      <pubDate>Tue, 18 Dec 2018 13:03:44 +0800</pubDate>
      
      <guid>/post/prototype-of-pair-trading-strategy-for-silver-etfs/</guid>
      <description>&lt;p&gt;In these 2 weeks, I&amp;rsquo;ll deploy my pair trading algo strategy into my server.&lt;/p&gt;

&lt;p&gt;I modified the code below from a renowned quant trader, Ernest Chan. The basic idea is to find z-scores through moving average &amp;amp; moving SD of spread. If it&amp;rsquo;s more than absolute of z-score, I will either short or long the spread depending on the polarity.&lt;/p&gt;

&lt;p&gt;In the backtesting below (using a pair of silver ETFs as an example), I assumed a hypothetical amount of 10,000 dollars per trade.&lt;/p&gt;

&lt;p&gt;Results are pretty good with a healthy sharpe ratio of 2.7 in the training set and 1.6 in the testing set of data. Annualized return is approximately 26% (translates to 2600 dollars) for the test set.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post/img/equity_curve.png&#34; alt=&#34;/post/img/equity_curve.png&#34;&gt;
&lt;img src=&#34;/post/img/summary_stats.png&#34; alt=&#34;/post/img/summary_stats.png&#34;&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rm(list=ls()) # clear workspace

library(&#39;zoo&#39;)
library(&amp;quot;tidyr&amp;quot;)
library(&amp;quot;dplyr&amp;quot;)
require(&amp;quot;quantmod&amp;quot;)
require(&amp;quot;urca&amp;quot;)
require(&amp;quot;PerformanceAnalytics&amp;quot;)
source(&#39;R/util/calculateReturns.R&#39;)
source(&#39;R/util/calculateMaxDD.R&#39;)
source(&#39;R/util/backshift.R&#39;)
source(&#39;R/util/extract_stock_prices.R&#39;)

#List of silver etfs, SIVR, USV, SLV, DBS
stock1 = &amp;quot;SIVR&amp;quot;
stock2 = &amp;quot;USV&amp;quot;

start_date = &amp;quot;2014-12-30&amp;quot;
end_date = &amp;quot;2018-12-30&amp;quot;

prop_train = 0.65
enter_z_score = 2     #Can use nlmb to vary
exit_z_score = 1     #Can use nlmb to vary

trade_amount = 10000
finance_rates = 2.5/100

data1 = df_crawl_time_series(stock1, start_date, end_date)
data1 = subset(data1, select = c(&amp;quot;Date&amp;quot;, &amp;quot;Open&amp;quot;, &amp;quot;Close&amp;quot;))
data1$Date = as.Date(data1$Date)

data2 = df_crawl_time_series(stock2, start_date, end_date)
data2 = subset(data2, select = c(&amp;quot;Date&amp;quot;, &amp;quot;Open&amp;quot;, &amp;quot;Close&amp;quot;))
data2$Date = as.Date(data2$Date)

data1 = xts(data1[, -1], order.by = data1[, 1])
data2 = xts(data2[, -1], order.by = data2[, 1])

data = merge(data1, data2)
data = as.data.frame(data)
data = subset(data, !is.na(data$Close) &amp;amp; !is.na(data$Close.1))

#  define indices for training and test sets
trainset &amp;lt;- 1:as.integer(nrow(data) * prop_train)
testset &amp;lt;- (length(trainset)+1):nrow(data)

#Cointegration test--&amp;gt;See if test of r&amp;lt;=1 &amp;gt; threshold. If more cointegrating
jotest=ca.jo(data.frame(data$Close[trainset], data$Close.1[trainset]), type=&amp;quot;trace&amp;quot;, K=2, ecdet=&amp;quot;none&amp;quot;, spec=&amp;quot;longrun&amp;quot;)
summary(jotest)

is_coint = jotest@teststat[1] &amp;gt; jotest@cval[1,3]
if(is_coint){
  print(&amp;quot;This pair&#39;s training set is cointegrating&amp;quot;)
}else{
  print(&amp;quot;This pair&#39;s training set is not cointegrating&amp;quot;)  
}

#Hedge ratio
result &amp;lt;- lm(data$Close[trainset] ~ 0 + data$Close.1[trainset])
hedgeRatio &amp;lt;- coef(result) # 1.631

#Spread
data$spread &amp;lt;- data$Close - hedgeRatio * data$Close.1

##########################Calculate half life#############################
# Calculate half life of mean reversion (residuals)
# Calculate yt-1 and (yt-1-yt)
# pull residuals to a vector
spread_train = data$spread[trainset]
y.lag &amp;lt;- c(spread_train[2:length(spread_train)], 0) # Set vector to lag -1 day
y.lag &amp;lt;- y.lag[1:length(y.lag)-1] # As shifted vector by -1, remove anomalous element at end of vector
spread_train &amp;lt;- spread_train[1:length(spread_train)-1] # Make vector same length as vector y.lag
y.diff &amp;lt;- spread_train - y.lag # Subtract todays close from yesterdays close
y.diff &amp;lt;- y.diff [1:length(y.diff)-1] # Make vector same length as vector y.lag
prev.y.mean &amp;lt;- y.lag - mean(y.lag, na.rm = T) # Subtract yesterdays close from the mean of lagged differences
prev.y.mean &amp;lt;- prev.y.mean [1:length(prev.y.mean )-1] # Make vector same length as vector y.lag
final.df &amp;lt;- data.frame(y.diff,prev.y.mean) # Create final data frame

# Linear Regression With Intercept
result &amp;lt;- lm(y.diff ~ prev.y.mean, data = final.df)
half_life &amp;lt;- -log(2)/coef(result)[2]   #Looking at this to 

if(half_life &amp;lt; 3){
  half_life = 14
}

######################MA of Spread#################################
#Change this to half life for lookback--&amp;gt;https://flare9xblog.com/2017/11/02/pairs-trading-testing-for-conintergration-adf-johansen-test-half-life-of-mean-reversion/
#Try EMA too
data$spread = zoo::na.locf(data$spread)
data$spreadMean &amp;lt;- SMA(data$spread, round(half_life))
data$spreadStd &amp;lt;- runSD(data$spread, n = round(half_life), sample = TRUE, cumulative = FALSE)

# data$spreadMean &amp;lt;- mean(data$spread[trainset], na.rm = T)
# data$spreadStd &amp;lt;- sd(data$spread[trainset], na.rm = T)

data$zscore = (data$spread - data$spreadMean)/data$spreadStd

data$longs &amp;lt;- data$zscore &amp;lt;= -enter_z_score # buy spread when its value drops below 2 standard deviations.
data$shorts &amp;lt;- data$zscore &amp;gt;= enter_z_score # short spread when its value rises above 2 standard deviations.

#  exit any spread position when its value is within 1 standard deviation of its mean.
data$longExits   &amp;lt;- data$zscore &amp;gt;= -exit_z_score 
data$shortExits &amp;lt;- data$zscore &amp;lt;= exit_z_score 

#Signal
data$posL1 = NA
data$posL2 = NA
data$posS1 = NA
data$posS2 = NA

# initialize to 0
data$posL1[1] &amp;lt;- 0; data$posL2[1] &amp;lt;- 0
data$posS1[1] &amp;lt;- 0; data$posS2[1] &amp;lt;- 0

data$posL1[data$longs] &amp;lt;- 1
data$posL2[data$longs] &amp;lt;- -1

data$posS1[data$shorts] &amp;lt;- -1
data$posS2[data$shorts] &amp;lt;- 1

data$posL1[data$longExits] &amp;lt;- 0
data$posL2[data$longExits] &amp;lt;- 0
data$posS1[data$shortExits] &amp;lt;- 0
data$posS2[data$shortExits] &amp;lt;- 0

#positions
data$posL1 &amp;lt;- zoo::na.locf(data$posL1); data$posL2 &amp;lt;- zoo::na.locf(data$posL2)
data$posS1 &amp;lt;- zoo::na.locf(data$posS1); data$posS2 &amp;lt;- zoo::na.locf(data$posS2)
data$position1 &amp;lt;- data$posL1 + data$posS1
# data$position1 = -data$position1    #Don&#39;t know why. It should be flipped!!!

data$position2 &amp;lt;- data$posL2 + data$posS2
# data$position2 = -data$position2    #Don&#39;t know why. It should be flipped!!!

#Returns
data$dailyret1 &amp;lt;- ROC(data$Close) #  last row is [385,] -0.0122636689 -0.0140365802
data$dailyret2 &amp;lt;- ROC(data$Close.1) #  last row is [385,] -0.0122636689 -0.0140365802

#Backshifting here. But signal is for following day returns!. So can still use latest Z-score
data$date = as.Date(row.names(data))
data = xts(data[,-which(names(data) == &amp;quot;date&amp;quot;)], order.by = data[, which(names(data) == &amp;quot;date&amp;quot;)])

data$pnl = lag(data$position1, 1) * data$dailyret1  + lag(data$position2, 1) * data$dailyret2

#Sharpe ratio
sharpeRatioTrainset &amp;lt;- sqrt(252)*mean(data$pnl[trainset], na.rm = TRUE)/sd(data$pnl[trainset], na.rm = TRUE)
sharpeRatioTrainset

sharpeRatioTestset &amp;lt;- sqrt(252)*mean(data$pnl[testset], na.rm = TRUE)/sd(data$pnl[testset], na.rm = TRUE)
sharpeRatioTestset 

#Performance analytics
charts.PerformanceSummary(data$pnl[testset])
table.Drawdowns(data$pnl[testset])
table.DownsideRisk(data$pnl[testset])
table.AnnualizedReturns(data$pnl[testset])

#Number of days not in the market
sum(data$pnl == 0, na.rm = T)/length(data$pnl)

#Putting a trade indicator
data$trade_indicator = lag(ifelse(data$position2 != 0 &amp;amp; !is.na(data$position2), 1, 0))

#Putting a unique id
count = 0
data$trade_id = NA

for(i in 2:nrow(data)){ 
  if(as.numeric(data$trade_indicator[i-1]) == 0 &amp;amp; as.numeric(data$trade_indicator[i]) != 0){
    count = count + 1
    data$trade_id[i] = count
  }else if(as.numeric(data$trade_indicator[i-1]) != 0 &amp;amp; as.numeric(data$trade_indicator[i]) != 0){
    data$trade_id[i] = count
  }
}

#Simple trade statistics
data$test = 0; data$test[testset] = 1 
data$pnl_add1 = data$pnl + 1
data_trade = as.data.frame(data)
data_trade_stats = data_trade %&amp;gt;%
  group_by(trade_id, test) %&amp;gt;%
  summarize(trade_duration = n(),
            cum_pnl = prod(pnl_add1, na.rm = T))

data_trade_stats$cum_pnl = data_trade_stats$cum_pnl - 1
data_trade_stats$profit_per_trade = data_trade_stats$cum_pnl * trade_amount

#Financing charges --&amp;gt;Depends on length of days
data_trade_stats$finance_fees =  trade_amount * finance_rates * (data_trade_stats$trade_duration/365)

#Commission fees
data_trade_stats$comm_fess = 4  #2 for 1 pair

#Net profit
data_trade_stats$profit_per_trade_less_comms = data_trade_stats$profit_per_trade - data_trade_stats$finance_fees - data_trade_stats$comm_fess

#Average loss
data_trade_stats = data_trade_stats[-which(is.na(data_trade_stats)), ]

data_trade_stats %&amp;gt;%
  group_by(test) %&amp;gt;%
  summarize(sum_profits = sum(profit_per_trade_less_comms), 
            mean_profits = mean(profit_per_trade_less_comms),
            na.rm = T)

sum(data_trade_stats$profit_per_trade_less_comms &amp;lt; 0)/ nrow(data_trade_stats)

summary(data_trade_stats$profit_per_trade_less_comms)

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Summary of My Computational Photography Module From Georgia Tech Computer Science Masters</title>
      <link>/post/summary-of-my-computational-photography-from-georgia-tech-computer-science-masters/</link>
      <pubDate>Sat, 08 Dec 2018 01:11:52 +0800</pubDate>
      
      <guid>/post/summary-of-my-computational-photography-from-georgia-tech-computer-science-masters/</guid>
      <description>&lt;p&gt;For what&amp;rsquo;s worth, here is a summary of what I went through for my Georgia Tech Computer Science Msc Computational Photography module.&lt;/p&gt;

&lt;p&gt;And it&amp;rsquo;s really painful but rewarding!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post/img/CP_1.png&#34; alt=&#34;/post/img/CP_1.png&#34;&gt;
&lt;img src=&#34;/post/img/CP_2.png&#34; alt=&#34;/post/img/CP_2.png&#34;&gt;
&lt;img src=&#34;/post/img/CP_3.png&#34; alt=&#34;/post/img/CP_3.png&#34;&gt;
&lt;img src=&#34;/post/img/CP_4.png&#34; alt=&#34;/post/img/CP_4.png&#34;&gt;
&lt;img src=&#34;/post/img/CP_5.png&#34; alt=&#34;/post/img/CP_5.png&#34;&gt;
&lt;img src=&#34;/post/img/CP_6.png&#34; alt=&#34;/post/img/CP_6.png&#34;&gt;
&lt;img src=&#34;/post/img/CP_7.png&#34; alt=&#34;/post/img/CP_7.png&#34;&gt;
&lt;img src=&#34;/post/img/CP_8.png&#34; alt=&#34;/post/img/CP_8.png&#34;&gt;
&lt;img src=&#34;/post/img/CP_9.png&#34; alt=&#34;/post/img/CP_9.png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Colorization</title>
      <link>/post/colorization/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/colorization/</guid>
      <description>

&lt;h2 id=&#34;colorization&#34;&gt;Colorization&lt;/h2&gt;

&lt;p&gt;The following is a high level project pipeline of my Computational Photography Colorization report. The project scope involves minimizing a quadratic cost function. An artist would only need to make a few colour scribble on a grey photograph and the algorithm will automatically populate the entire photograph with the associated colours.&lt;/p&gt;

&lt;p&gt;1.Input: I first read in the image using imread function.&lt;/p&gt;

&lt;p&gt;2.Find the difference: Next I compute the difference between the marked and grey scale image. This would feed into step 5.&lt;/p&gt;

&lt;p&gt;3.Transform to YIQ space: Then I convert the grey image and the marked version from RGB space to YIQ space 2 &amp;amp; 3 . I wrote a function, rgbToyiq in color_space.py to convert rgb dimension to that of YIQ.&lt;/p&gt;

&lt;p&gt;4.Compute weight matrix:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The next step, also the most complicated one is to compute the weight matrix.&lt;/li&gt;
&lt;li&gt;I first initialize 3 matrices of size height X width X size of window (9): row indices (i, j count), colIndices and values (weights) to hold key information during the loop&lt;/li&gt;
&lt;li&gt;The algo will loop through each pixel. And it will compute the weights (using marked) according to formula below in a window of size 9 i.e. 9 pixels in a window (including the pixel).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;5.Solve Ax = B: Once the weights are obtained, I proceed to obtain a least square solution.&lt;/p&gt;

&lt;p&gt;6.Lastly, I transform the YIQ output back to RGB space.&lt;/p&gt;

&lt;p&gt;Here are the photographs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post/img/baby.bmp&#34; alt=&#34;/post/img/baby.bmp&#34;&gt;
&lt;img src=&#34;/post/img/baby_marked.bmp&#34; alt=&#34;/post/img/baby_marked.bmp&#34;&gt;
&lt;img src=&#34;/post/img/baby_colorized.bmp&#34; alt=&#34;/post/img/baby_colorized.bmp&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Architecture and Process Flow for My Algorithmic Trading</title>
      <link>/post/architecture-and-process-flow-for-my-algorithmic-trading/</link>
      <pubDate>Sun, 04 Nov 2018 10:19:13 +0800</pubDate>
      
      <guid>/post/architecture-and-process-flow-for-my-algorithmic-trading/</guid>
      <description>

&lt;h2 id=&#34;project-that-i-will-be-working-in-2018-2019&#34;&gt;Project that I will be working in 2018-2019&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;/post/img/mvp_algo_trading.png&#34; alt=&#34;/post/img/mvp_algo_trading.png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Seam Carving</title>
      <link>/post/seam-carving/</link>
      <pubDate>Thu, 25 Oct 2018 13:23:23 +0800</pubDate>
      
      <guid>/post/seam-carving/</guid>
      <description>

&lt;h2 id=&#34;snippet-of-my-seam-carving-report-from-my-msc-computer-science-georgia-tech-s-computational-photography-module&#34;&gt;Snippet of my Seam Carving Report from my Msc Computer Science Georgia Tech&amp;rsquo;s Computational Photography module&lt;/h2&gt;

&lt;p&gt;Besides removing of streams, we can also add streams. We identify k streams for removal and duplicate by averaging the left and right neighbours. The computation of these averages is done by convolving the following matrix with the images’ colour channels.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kernel = np.array([[0, 0, 0],
         [0.5, 0, 0.5],
         [0, 0, 0]])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the implementation of my scaling_up algorithm, I first remove k streams (depending on ratio set by user) and recorded the coordinates and cumulative energy values of the original picture in each removal.&lt;/p&gt;

&lt;p&gt;Then I reverse the whole process by adding the stream back together with the averaged values of neighbours&lt;/p&gt;

&lt;p&gt;I implemented this scaling_up algorithn for the dolphin pictures.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;8(a) is the original picture&lt;/li&gt;
&lt;li&gt;8&amp;copy; Enlarged picture with added streams: python main.py fig8 u c 1.5 y&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;8(d) Enalrged picture without added streams: python main.py fig8 u c 1.5 n&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;8(f) Enlarged picture with scaling up algorithm implemented twice: python main.py fig8_processed u c 1.5 n&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Figure 8(a), 8&amp;copy;, 8(d), (f)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post/img/seam_carving.img.png&#34; alt=&#34;/post/img/seam_carving.img.png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>R package: Decomposing a Position Into Exchange Rate and Non Exchange Rate Effects</title>
      <link>/post/decomposing-a-position-into-exchange-rate-and-non-exchange-rate-effects/</link>
      <pubDate>Thu, 25 Oct 2018 11:39:24 +0800</pubDate>
      
      <guid>/post/decomposing-a-position-into-exchange-rate-and-non-exchange-rate-effects/</guid>
      <description>

&lt;h2 id=&#34;decomposing-a-position-into-exchange-rate-and-non-exchange-rate-effects&#34;&gt;Decomposing a Position Into Exchange Rate and Non Exchange Rate Effects&lt;/h2&gt;

&lt;p&gt;If you are someone with a stake in foreign positions, this package I wrote here may be a useful tool to help you understand the impact of foreign currency on your positions. For instance,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If you are an investor, you may use it to analyze impact of exchange rate on your investment positions.&lt;/li&gt;
&lt;li&gt;If you are in the treasury department, you may wish to analyze the impact of exchange rates on your bonds.&lt;/li&gt;
&lt;li&gt;If you are in the finance department, you could analyze the exchange rate impact on your foreign revenue.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To start using this package, you may first install the devtools package and execute the following command. install_github(&amp;ldquo;jironghuang/RemoveExchangeRateEffects&amp;rdquo;). The R documentation is as follows,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post/img/exch_documentation1.png&#34; alt=&#34;/post/img/exch_documentation1.png&#34;&gt;
&lt;img src=&#34;/post/img/exch_documentation2.png&#34; alt=&#34;/post/img/exch_documentation2.png&#34;&gt;&lt;/p&gt;

&lt;p&gt;You may follow the 2 examples to better understand how this package works.&lt;/p&gt;

&lt;h3 id=&#34;example-1&#34;&gt;Example 1&lt;/h3&gt;

&lt;p&gt;In summary, what the example does below is to decompose 1 instrument position in SGD (column value) - from the perspective of someone staying in Singapore - into local static value (i.e if I keep the exchange rate constant at the start of the period) and the residual exchange rate impact.&lt;/p&gt;

&lt;p&gt;If you look at the value at the end of the period (Oct 2018), you would notice that the value in SGD fell from 331 to 261. From the perspective of a Singaporean local - through this package -  we can understand that the appreciation in USD negate the fall in value by 4 SGD.&lt;/p&gt;

&lt;p&gt;If you are an economist, you could have considered the exchange rate elasticities. But let&amp;rsquo;s ignore that for now.&lt;/p&gt;

&lt;h3 id=&#34;quick-example-1-in-r-codes-decomposing-a-single-instrument&#34;&gt;Quick example 1 in R codes (decomposing a single instrument)&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;library(devtools)
install_github(&amp;quot;jironghuang/RemoveExchangeRateEffects&amp;quot;)
library(RemoveExchangeRateEffects)

sp_exch_rate_pair = &amp;quot;USDSGD=X&amp;quot;  #exchange rate pair. e.g &amp;quot;USDSGD=X&amp;quot;. &amp;quot;&amp;lt;Foreign_currency&amp;gt;&amp;lt;local_currency&amp;gt;=X&amp;quot;

ap_start_date &amp;lt;- as.Date(&amp;quot;2017-10-01&amp;quot;)  #starting date of portfolio e.g. 2017-10-01
ap_end_date &amp;lt;- as.Date(&amp;quot;2020-10-01&amp;quot;) #ending date of portfolio e.g. 2020-10-01. If you include a date beyond current date, the function will use the current date instead
np_mthly_yearly = &amp;quot;monthly&amp;quot;  #alternatively this could be &amp;quot;yearly&amp;quot;&amp;quot;

data(eg_dat) #example dataset that I included in this package
dp_dates_investment_value = instrument
o_exchRate_effect &amp;lt;- exchange_rate_decomposition(sp_exch_rate_pair, ap_start_date, ap_end_date, np_mthly_yearly, dp_dates_investment_value)
o_exchRate_effect$get_portfolio()

    value_in_sgd exchange_rate fgn_value local_static_value exch_rate_impact
Oct 2017 331.53   1.36010  243.7541           331.5300        0.0000000
Nov 2017 308.85   1.34670  229.3384           311.9231       -3.0731344
Dec 2017 311.35   1.33780  232.7328           316.5399       -5.1899425
Jan 2018 354.31   1.31168  270.1192           367.3892      -13.0791734
Feb 2018 343.06   1.32433  259.0442           352.3260       -9.2660108
Mar 2018 266.13   1.31090  203.0132           276.1183       -9.9882495
Apr 2018 293.90   1.32577  221.6825           301.5104       -7.6103599
May 2018 284.73   1.33850  212.7232           289.3248       -4.5948212
Jun 2018 342.95   1.36830  250.6395           340.8948        2.0552438
Jul 2018 298.14   1.36140  218.9952           297.8553        0.2846937
Aug 2018 301.66   1.36700  220.6730           300.1374        1.5226438
Sep 2018 264.77   1.36732  193.6416           263.3719        1.3980921
Oct 2018 260.95   1.38061  189.0107           257.0734        3.8766087

o_exchRate_effect$get_diff_portfolio_value()
[1] 3.8766087
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;example-2&#34;&gt;Example 2&lt;/h3&gt;

&lt;p&gt;The second example builds upon the first. I&amp;rsquo;ve expanded the previous function to decompose multiple instruments at once.&lt;/p&gt;

&lt;p&gt;get_full_decomposition() returns a list of data frames with the decompositions.&lt;/p&gt;

&lt;p&gt;But before you implement the function above, you would have to add the information via the mutator functions as shown in the example below (the functions with the prefix set)&lt;/p&gt;

&lt;h3 id=&#34;quick-example-2-in-r-codes-decomposing-multiple-instruments-at-1-time&#34;&gt;Quick example 2 in R codes (Decomposing multiple instruments at 1 time)&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;data(eg_dat)

er = c(&amp;quot;USDSGD=X&amp;quot;, &amp;quot;GBPSGD=X&amp;quot;)
start_date = c(&amp;quot;2017-10-01&amp;quot;, &amp;quot;2017-10-01&amp;quot;)
end_date = c(&amp;quot;2020-10-01&amp;quot;, &amp;quot;2020-10-01&amp;quot;)
freq = c(&amp;quot;monthly&amp;quot;, &amp;quot;monthly&amp;quot;)
dat = list(eg_dat, eg_dat)


o_exchRate_effect &amp;lt;- multiple_exchange_rate_decomposition(2)
o_exchRate_effect$set_sa_exch_rate_pair(er) #adding an array of exchange rate pairs
o_exchRate_effect$set_sa_start_date(start_date) #adding an array of starting dates
o_exchRate_effect$set_sa_end_date(end_date) #adding an array of ending dates
o_exchRate_effect$set_sa_mthly_yearly(freq) #adding an array of &amp;quot;monthly&amp;quot; or &amp;quot;yearly&amp;quot; option
o_exchRate_effect$set_dl_dates_investment_value(dat) #adding list of data frames
o_exchRate_effect$get_full_decomposition()  #carry out decomposition and obtain a list of data frames

[[1]]
          value exchange_rate fgn_value local_static_value exch_rate_impact
Oct 2017 331.53       1.36010  243.7541           331.5300        0.0000000
Nov 2017 308.85       1.34670  229.3384           311.9231       -3.0731344
Dec 2017 311.35       1.33780  232.7328           316.5399       -5.1899425
Jan 2018 354.31       1.31168  270.1192           367.3892      -13.0791734
Feb 2018 343.06       1.32433  259.0442           352.3260       -9.2660108
Mar 2018 266.13       1.31090  203.0132           276.1183       -9.9882495
Apr 2018 293.90       1.32577  221.6825           301.5104       -7.6103599
May 2018 284.73       1.33850  212.7232           289.3248       -4.5948212
Jun 2018 342.95       1.36830  250.6395           340.8948        2.0552438
Jul 2018 298.14       1.36140  218.9952           297.8553        0.2846937
Aug 2018 301.66       1.36700  220.6730           300.1374        1.5226438
Sep 2018 264.77       1.36732  193.6416           263.3719        1.3980921
Oct 2018 260.95       1.38061  189.0107           257.0734        3.8766087

[[2]]
          value exchange_rate fgn_value local_static_value exch_rate_impact
Oct 2017 331.53       1.79703  184.4877           331.5300        0.0000000
Nov 2017 308.85       1.80690  170.9281           307.1629        1.6870605
Dec 2017 311.35       1.79812  173.1531           311.1613        0.1887369
Jan 2018 354.31       1.85680  190.8175           342.9048       11.4051640
Feb 2018 343.06       1.84162  186.2816           334.7537        8.3062984
Mar 2018 266.13       1.83911  144.7059           260.0408        6.0892228
Apr 2018 293.90       1.82588  160.9635           289.2562        4.6437963
May 2018 284.73       1.77878  160.0704           287.6513       -2.9212846
Jun 2018 342.95       1.78907  191.6918           344.4759       -1.5258666
Jul 2018 298.14       1.78638  166.8962           299.9175       -1.7774444
Aug 2018 301.66       1.77860  169.6053           304.7858       -3.1258259
Sep 2018 264.77       1.78285  148.5094           266.8759       -2.1058633
Oct 2018 260.95       1.76900  147.5127           265.0848       -4.1347817

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Shift Share Analysis Package I developed</title>
      <link>/post/shift-share-analysis-package/</link>
      <pubDate>Sat, 22 Sep 2018 12:23:28 +0800</pubDate>
      
      <guid>/post/shift-share-analysis-package/</guid>
      <description>

&lt;h2 id=&#34;shift-share-analysis-package-i-developed&#34;&gt;Shift-share Analysis Package I developed&lt;/h2&gt;

&lt;p&gt;During my career, I often have to deal with compositional &amp;amp; within group effects. For instance, the employment rate fell by 3% across 2 period. How much of it is due to an increase in employment rate within the sub-group and how much of it is due to compositional shift (for example ageing population).&lt;/p&gt;

&lt;p&gt;A formal way to explain these effects is known as shift-share analysis. It allows you to decompose percentage point change or absolute changes (WIP) into within group and across group effects.&lt;/p&gt;

&lt;p&gt;A package currently used in the R community is REAT, but it doesn&amp;rsquo;t allow you to decompose the effects into finer categories. Hence, I hope this package developed here is able to fill up the gap.&lt;/p&gt;

&lt;p&gt;Some examples that you may use this tool are,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Employment rate&lt;/li&gt;
&lt;li&gt;Demographics rate&lt;/li&gt;
&lt;li&gt;Basketball field goal % decomposed into 2 point vs 3 point&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To start using this package, you may first install the devtools package and execute the following command. install_github(&amp;ldquo;jironghuang/shiftshare&amp;rdquo;).&lt;/p&gt;

&lt;p&gt;And if you are interested in the codes used to develop the package, you may visit the following link &lt;a href=&#34;https://github.com/jironghuang/shiftshare&#34; target=&#34;_blank&#34;&gt;https://github.com/jironghuang/shiftshare&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You may follow the example to better understand how this package works. Essentially, what the example does is to decomposte the 29.7% point change into 3 effects. Within effect == 68.8%,  Across_effect == -7.4% and Dynamic Effect == -31.8%&lt;/p&gt;

&lt;h3 id=&#34;quick-example&#34;&gt;Quick example&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;emp1 = c(10, 20, 40, 50)
pop1 = c(40, 50, 60, 70)
emp2 = c(20, 30, 50, 60)
pop2 = c(50, 70, 20, 50)

ss_analysis &amp;lt;- shift_share(ap_grp_labels = c(&amp;quot;grp1&amp;quot;, &amp;quot;grp2&amp;quot;, &amp;quot;grp3&amp;quot;, &amp;quot;grp4&amp;quot;),
                           ap_numerator1 = emp1,
                           ap_numerator2 = emp2,
                           ap_denominator1 = pop1,
                           ap_denominator2 = pop2)
                           
&amp;gt; ss_analysis$get_effects()
  grp_labels     prop1     prop2     rate1     rate2 within_effect across_effect dynamic_effect overall_effect
1       grp1 0.1818182 0.2631579 0.2500000 0.4000000   0.027272727    0.02033493    0.012200957     0.05980861
2       grp2 0.2272727 0.3684211 0.4000000 0.4285714   0.006493506    0.05645933    0.004032809     0.06698565
3       grp3 0.2727273 0.1052632 0.6666667 2.5000000   0.500000000   -0.11164274   -0.307017544     0.08133971
4       grp4 0.3181818 0.2631579 0.7142857 1.2000000   0.154545455   -0.03930280   -0.026725906     0.08851675  

&amp;gt; ss_analysis$get_agg_effects()
         Description within_effect across_effect dynamic_effect overall_effect
1 aggregated_effects     0.6883117   -0.07415129     -0.3175097      0.2966507

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Automated Email Notification of my ETF watchlist</title>
      <link>/post/automated_email_notification/</link>
      <pubDate>Tue, 04 Sep 2018 01:37:53 +0800</pubDate>
      
      <guid>/post/automated_email_notification/</guid>
      <description>&lt;p&gt;I wrote an automated email notification code to send out my daily ETF watchlist in csv - an extension of my ETF watchlist project &lt;a href=&#34;http://jirong-huang.netlify.com/project/watch_list/&#34;&gt;here&lt;/a&gt;. I figured out that people will not visit my site. So why not blast out the watchlist instead:)&lt;/p&gt;

&lt;p&gt;And if you are interested in the code. Here you go.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#Steps for sending watchlist
library(&amp;quot;rJava&amp;quot;)
library(&#39;mailR&#39;)

source(&amp;quot;./R/emails.R&amp;quot;)

# Write the content of your email
msg &amp;lt;- paste(&amp;quot;Hey there, I&#39;m sending this ETF watchlist that is updated as of &amp;quot;, 
             &amp;quot;\n&amp;quot;,
             as.character(date()),
             &amp;quot;\n&amp;quot;,
             &amp;quot;This is part of my daily automated ETF dashboard + Email notification and I thought you may be interested in it. See the following link for more details: http://jirong-huang.netlify.com/project/watch_list/&amp;quot;,
             &amp;quot;\n&amp;quot;,
             &amp;quot;If this irritates you too much, let me know and I can take you out of this mailing list:)&amp;quot;,&amp;quot;&amp;quot;,&amp;quot;Best,&amp;quot;,&amp;quot;Jirong&amp;quot;, sep = &amp;quot;\n&amp;quot;)

# Define who the sender is
sender &amp;lt;- &amp;quot;jironghuang88@gmail.com&amp;quot;
# Define who should get your email
recipients &amp;lt;- emails
              # Send your email with the send.mail function
              send.mail(from = sender,
                        to = recipients,
                        subject = &amp;quot;ETF Watchlist&amp;quot;,
                        body = msg,
                        attach.files = &amp;quot;./Output/yahoo_crawled_data.csv&amp;quot;,
                        smtp = list(host.name = &amp;quot;smtp.gmail.com&amp;quot;, port = 587,
                                    user.name = &amp;quot;jironghuang88@gmail.com&amp;quot;,
                                    passwd = Sys.getenv(&amp;quot;mail&amp;quot;), ssl = TRUE),
                        authenticate = TRUE,
                        send = TRUE)
              
              # JAVA_HOME /usr/lib/jvm/java-8-oracle             
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Asset Alllocation</title>
      <link>/asset_allocation/asset_allocation/</link>
      <pubDate>Sun, 02 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/asset_allocation/asset_allocation/</guid>
      <description>&lt;p&gt;This section indicates my overall current asset allocation, not based on any quantitative analysis but based on rule-of-thumb from wealth management community.&lt;/p&gt;

&lt;iframe src=&#34;https://docs.google.com/spreadsheets/d/e/2PACX-1vQtSJfzakpUWRkryIoXaqJm7szd-g6R1SHr-aAXAlHNOFEDXYGhCBNC9UeYEYv8cYf8krgsS6LPpED9/pubchart?oid=963907902&amp;amp;format=interactive&#34; width=&#34;1000&#34; height=&#34;1000&#34; frameborder=&#34;0&#34; marginheight=&#34;0&#34; marginwidth=&#34;0&#34;&gt;Loading...&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Naming Conventions in R. Let&#39;s call it JR Notations</title>
      <link>/post/jr-naming-conventions-in-r/</link>
      <pubDate>Sun, 26 Aug 2018 14:09:02 +0800</pubDate>
      
      <guid>/post/jr-naming-conventions-in-r/</guid>
      <description>

&lt;h2 id=&#34;naming-conventions-in-r-let-s-call-it-jr-notations&#34;&gt;Naming Conventions in R. Let&amp;rsquo;s call it JR Notations.&lt;/h2&gt;

&lt;p&gt;&amp;lsquo;Naming conventions&amp;rsquo; is a huge thing in many programming languages/ paradigms/ communities. But it&amp;rsquo;s noticeably absent in the R programming community.&lt;/p&gt;

&lt;p&gt;With some inspiration from the Hungarian Notation, here&amp;rsquo;s a blue-print that I came up with while working on a major R project over the last 2 months. Drumroll please&amp;hellip;&lt;/p&gt;

&lt;h3 id=&#34;1-naming-conventions-for-r-scripts&#34;&gt;1. Naming conventions for R scripts&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;F_ for R scripts that contains functions.&lt;/li&gt;
&lt;li&gt;O_ for R scripts that contains classes.&lt;/li&gt;
&lt;li&gt;P_ for R scripts that runs the procedures.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;2-naming-conventions-for-r-functions-at-the-start-of-the-function-name&#34;&gt;2. Naming conventions for R functions. At the start of the function name,&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;bf stands for a return in boolean value&lt;/li&gt;
&lt;li&gt;sf stands for a return in string value&lt;/li&gt;
&lt;li&gt;nf stands for a return in numeric value&lt;/li&gt;
&lt;li&gt;mf stands for a return in matrix values&lt;/li&gt;
&lt;li&gt;lf stands for a return in list values&lt;/li&gt;
&lt;li&gt;af stands for a return in array values&lt;/li&gt;
&lt;li&gt;df stands for a return in data frame&lt;/li&gt;
&lt;li&gt;vf stands for a void function. i.e. executing a function without returning a variable.&lt;/li&gt;
&lt;li&gt;gf stands for a return in graph value&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;3-naming-conventions-for-parameters-in-functions&#34;&gt;3. Naming conventions for parameters in functions&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;bp stands for boolean parameter&lt;/li&gt;
&lt;li&gt;sp stands for string parameter&lt;/li&gt;
&lt;li&gt;np stands for numeric parameter&lt;/li&gt;
&lt;li&gt;mp stands for matrix parameter&lt;/li&gt;
&lt;li&gt;lp stands for list parameter&lt;/li&gt;
&lt;li&gt;ap stands for array parameter&lt;/li&gt;
&lt;li&gt;dp stands for data frame parameter&lt;/li&gt;
&lt;li&gt;gp stands for a return in graph parameter&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;4-naming-conventions-for-r-variables&#34;&gt;4. Naming conventions for R variables&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;b stands for boolean variable&lt;/li&gt;
&lt;li&gt;s stands for string variable&lt;/li&gt;
&lt;li&gt;n stands for numeric variable&lt;/li&gt;
&lt;li&gt;m stands for matrix variable&lt;/li&gt;
&lt;li&gt;l stands for list variable&lt;/li&gt;
&lt;li&gt;a stands for array variable&lt;/li&gt;
&lt;li&gt;d stands for data frame variable&lt;/li&gt;
&lt;li&gt;g stands for graph variable&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;5-naming-conventions-for-r-global-variables&#34;&gt;5. Naming conventions for R global variables&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;bg stands for boolean global variable&lt;/li&gt;
&lt;li&gt;sg stands for string global variable&lt;/li&gt;
&lt;li&gt;ng stands for numeric global variable&lt;/li&gt;
&lt;li&gt;mg stands for matrix global variable&lt;/li&gt;
&lt;li&gt;lg stands for list global variable&lt;/li&gt;
&lt;li&gt;ag stands for array global variable&lt;/li&gt;
&lt;li&gt;dg stands for data frame global variable&lt;/li&gt;
&lt;li&gt;gg stands for global graph variable&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Skin in the Game</title>
      <link>/skin/skin-in-the-game/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/skin/skin-in-the-game/</guid>
      <description>&lt;p&gt;In this section, I&amp;rsquo;ll note all the quantitative decisions I have made in the areas of investing, trading and betting. Money allocated here excludes the portion that I placed in conservative asset allocation.&lt;/p&gt;

&lt;p&gt;Skin in the game or put in another way - putting where your mouth aligns with my core belief. Any serious analysis that I feel strongly about should have a stake in the game.&lt;/p&gt;

&lt;p&gt;Also, I&amp;rsquo;m of the view that if you make enough calculated bets with positive expected returns in your life, eventually it will be a net positive in the long run.&lt;/p&gt;

&lt;iframe src=&#34;https://docs.google.com/spreadsheets/d/e/2PACX-1vQtSJfzakpUWRkryIoXaqJm7szd-g6R1SHr-aAXAlHNOFEDXYGhCBNC9UeYEYv8cYf8krgsS6LPpED9/pubhtml?gid=606546538&amp;amp;single=true&amp;amp;widget=true&amp;amp;headers=false&#34; width=&#34;1000&#34; height=&#34;1000&#34; frameborder=&#34;0&#34; marginheight=&#34;0&#34; marginwidth=&#34;0&#34;&gt;Loading...&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>If you&#39;re interested in the content, please subscribe here</title>
      <link>/subscribe/subscribe/</link>
      <pubDate>Sun, 12 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/subscribe/subscribe/</guid>
      <description>


&lt;iframe src=&#34;https://docs.google.com/forms/d/e/1FAIpQLSddfEPQE7LHMi7MdfzPx6tJL_KPDKsEpLOloPHY9R04-n48sQ/viewform?usp=sf_link&#34; width=&#34;1000&#34; height=&#34;1000&#34; frameborder=&#34;0&#34; marginheight=&#34;0&#34; marginwidth=&#34;0&#34;&gt;
Loading…
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Investment compass</title>
      <link>/project/investment_compass_guidance/</link>
      <pubDate>Thu, 09 Aug 2018 21:30:46 +0800</pubDate>
      
      <guid>/project/investment_compass_guidance/</guid>
      <description>

&lt;h2 id=&#34;investment-compass-kindly-wait-10-seconds-for-the-entire-app-to-load-best-viewed-in-desktop&#34;&gt;Investment Compass (Kindly wait 10 seconds for the entire app to load. Best viewed in Desktop)&lt;/h2&gt;

&lt;p&gt;This serves as a compass for me to visualize the potential returns given the % fall from 52 week high. See my linkedin article &lt;a href=&#34;https://www.linkedin.com/pulse/investment-compass-our-volatile-times-jirong-huang/&#34;&gt;here&lt;/a&gt; for further explanation on why I think this is a good indicator.&lt;/p&gt;

&lt;p&gt;The app consists of 3 tabs. The &amp;lsquo;Visualize&amp;rsquo; tab contains 3 graphs plotting % fall from 52 week high against the expected returns 1 to 3 years later. And the value boxes are simply the fitted values from the best fit lines.&lt;/p&gt;

&lt;p&gt;The second tab contains the description of the indexes. For eg. ^STI refers to Straits Times Index. It will be useful for selection of the Index under Visualization tab.&lt;/p&gt;

&lt;p&gt;The third tab is just a summary of the Linkedin article.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re interested in reading the codes, pls visit my github &lt;a href=&#34;https://github.com/jironghuang/investment_compass&#34;&gt;link&lt;/a&gt;. At the moment, the lagging of indicators are done in a grossly inefficient way because I was just cobbling together some codes I did in the past. Will optimize it by using parallelized functions like mclapply in the future (used for crawling the stock process but not the computation).&lt;/p&gt;

&lt;iframe src=&#34;https://sef88.shinyapps.io/investment_compass/&#34; width=&#34;1200&#34; height=&#34;1500&#34; style=&#34;border: none;&#34;&gt;&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Rolling out the Investment Compass interactive app that I promised eons ago</title>
      <link>/post/rolling-out-the-investment-compass-interactive-app-that-i-promised-to-myself-eons-ago/</link>
      <pubDate>Sun, 05 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/rolling-out-the-investment-compass-interactive-app-that-i-promised-to-myself-eons-ago/</guid>
      <description>&lt;p&gt;Finally I had some time to sit down to work on the interactive app. From what was an hideous app to a somewhat Minimum Viable Product (MVP) version of an app. (Shhh&amp;hellip;I&amp;rsquo;m not really a User Interface, UI person).&lt;/p&gt;

&lt;p&gt;This serves as a compass for me to visualize the potential returns given the % fall from 52 week high. See my linkedin article &lt;a href=&#34;https://www.linkedin.com/pulse/investment-compass-our-volatile-times-jirong-huang/&#34;&gt;here&lt;/a&gt; for further explanation on why I think this is a good indicator.&lt;/p&gt;

&lt;p&gt;The app consists of 3 tabs. The &amp;lsquo;Visualize&amp;rsquo; tab contains 3 graphs plotting % fall from 52 week high against the expected returns 1 to 3 years later. And the value boxes are simply the fitted values from the best fit lines.&lt;/p&gt;

&lt;p&gt;The second tab contains the description of the indexes. For eg. ^STI refers to Straits Times Index. It will be useful for selection of the Index under Visualization tab.&lt;/p&gt;

&lt;p&gt;The third tab is just a summary of the Linkedin article.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re interested in reading the codes, pls visit my github &lt;a href=&#34;https://github.com/jironghuang/investment_compass&#34;&gt;link&lt;/a&gt;. At the moment, the lagging of indicators are done in a grossly inefficient way because I was just cobbling together some codes I did in the past. Will optimize it by using parallelized functions like mclapply in the future (used for crawling the stock process but not the computation).&lt;/p&gt;

&lt;iframe src=&#34;https://sef88.shinyapps.io/investment_compass/&#34; width=&#34;1200&#34; height=&#34;1500&#34; style=&#34;border: none;&#34;&gt;&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Updated ETF project codes</title>
      <link>/post/etf_watchlist_project/</link>
      <pubDate>Sat, 07 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/etf_watchlist_project/</guid>
      <description>


&lt;div id=&#34;updated-etf-watchlist-project&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Updated ETF watchlist project&lt;/h2&gt;
&lt;p&gt;While watching a world cup match today, I updated my ETF watchlist project (you may click &lt;a href=&#34;/project/watch_list&#34;&gt;here&lt;/a&gt; if you haven’t seen it yet)&lt;/p&gt;
&lt;p&gt;You may find the github code &lt;a href=&#34;https://github.com/jironghuang/ETF_watchlist&#34;&gt;here&lt;/a&gt;. In the revision, I parallelized the crawling - essentially tapping on all the cores in my machines.&lt;/p&gt;
&lt;p&gt;To create your own watchlist. Follow these steps,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Install R and R studio.&lt;/li&gt;
&lt;li&gt;In Mac or Linux, type the following in command line git clone &lt;a href=&#34;https://github.com/jironghuang/ETF_watchlist&#34; class=&#34;uri&#34;&gt;https://github.com/jironghuang/ETF_watchlist&lt;/a&gt; . In windows, you may visit the link and download it as zipped folder&lt;/li&gt;
&lt;li&gt;Open the .Rproj&lt;/li&gt;
&lt;li&gt;Tweak the input file to change your watchlist. Ticker symbol should follow yahoo ticker naming convention (e.g. VWRD.L for the ETF listed on stock exchange)&lt;/li&gt;
&lt;li&gt;Ctrl + A and Ctrl + Enter. Or just click the run button in the top right hand of Rstudio&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note: For the auth.r section, you may comment it out if you do not wish to upload the crawled data in googlesheet.&lt;/p&gt;
&lt;iframe src=&#34;https://docs.google.com/spreadsheets/d/e/2PACX-1vQtSJfzakpUWRkryIoXaqJm7szd-g6R1SHr-aAXAlHNOFEDXYGhCBNC9UeYEYv8cYf8krgsS6LPpED9/pubhtml?gid=0&amp;amp;single=true&#34; width=&#34;900&#34; height=&#34;780&#34; style=&#34;border: none;&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
